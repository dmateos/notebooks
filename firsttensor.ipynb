{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Could not find directory train",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000004?line=25'>26</a>\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m# to clean up output cells\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000004?line=28'>29</a>\u001b[0m \u001b[39m# Load training and validation sets\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000004?line=29'>30</a>\u001b[0m ds_train_ \u001b[39m=\u001b[39m image_dataset_from_directory(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000004?line=30'>31</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000004?line=31'>32</a>\u001b[0m     labels\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39minferred\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000004?line=32'>33</a>\u001b[0m     label_mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mbinary\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000004?line=33'>34</a>\u001b[0m     image_size\u001b[39m=\u001b[39;49m[\u001b[39m128\u001b[39;49m, \u001b[39m128\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000004?line=34'>35</a>\u001b[0m     interpolation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mnearest\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000004?line=35'>36</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000004?line=36'>37</a>\u001b[0m     shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000004?line=37'>38</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000004?line=38'>39</a>\u001b[0m ds_valid_ \u001b[39m=\u001b[39m image_dataset_from_directory(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000004?line=39'>40</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000004?line=40'>41</a>\u001b[0m     labels\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minferred\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000004?line=45'>46</a>\u001b[0m     shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000004?line=46'>47</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000004?line=48'>49</a>\u001b[0m \u001b[39m# Data Pipeline\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/ai/lib/python3.8/site-packages/keras/utils/image_dataset.py:192\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mif\u001b[39;00m seed \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m   seed \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m1e6\u001b[39m)\n\u001b[0;32m--> 192\u001b[0m image_paths, labels, class_names \u001b[39m=\u001b[39m dataset_utils\u001b[39m.\u001b[39;49mindex_directory(\n\u001b[1;32m    193\u001b[0m     directory,\n\u001b[1;32m    194\u001b[0m     labels,\n\u001b[1;32m    195\u001b[0m     formats\u001b[39m=\u001b[39;49mALLOWLIST_FORMATS,\n\u001b[1;32m    196\u001b[0m     class_names\u001b[39m=\u001b[39;49mclass_names,\n\u001b[1;32m    197\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m    198\u001b[0m     seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    199\u001b[0m     follow_links\u001b[39m=\u001b[39;49mfollow_links)\n\u001b[1;32m    201\u001b[0m \u001b[39mif\u001b[39;00m label_mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(class_names) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    202\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    203\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mWhen passing `label_mode=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`, there must be exactly 2 \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    204\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mclass_names. Received: class_names=\u001b[39m\u001b[39m{\u001b[39;00mclass_names\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/ai/lib/python3.8/site-packages/keras/utils/dataset_utils.py:66\u001b[0m, in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m   subdirs \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 66\u001b[0m   \u001b[39mfor\u001b[39;00m subdir \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(tf\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mgfile\u001b[39m.\u001b[39;49mlistdir(directory)):\n\u001b[1;32m     67\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mjoin(directory, subdir)):\n\u001b[1;32m     68\u001b[0m       \u001b[39mif\u001b[39;00m subdir\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/.virtualenvs/ai/lib/python3.8/site-packages/tensorflow/python/lib/io/file_io.py:766\u001b[0m, in \u001b[0;36mlist_directory_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[39m\"\"\"Returns a list of entries contained within a directory.\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \n\u001b[1;32m    753\u001b[0m \u001b[39mThe list is in arbitrary order. It does not contain the special entries \".\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[39m  errors.NotFoundError if directory doesn't exist\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_directory(path):\n\u001b[0;32m--> 766\u001b[0m   \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mNotFoundError(\n\u001b[1;32m    767\u001b[0m       node_def\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    768\u001b[0m       op\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    769\u001b[0m       message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not find directory \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(path))\n\u001b[1;32m    771\u001b[0m \u001b[39m# Convert each element to string, since the return values of the\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[39m# vector of string should be interpreted as strings, not bytes.\u001b[39;00m\n\u001b[1;32m    773\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    774\u001b[0m     compat\u001b[39m.\u001b[39mas_str_any(filename)\n\u001b[1;32m    775\u001b[0m     \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m _pywrap_file_io\u001b[39m.\u001b[39mGetChildren(compat\u001b[39m.\u001b[39mpath_to_bytes(path))\n\u001b[1;32m    776\u001b[0m ]\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Could not find directory train"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "\n",
    "\n",
    "# Reproducability\n",
    "def set_seed(seed=31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed()\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')\n",
    "warnings.filterwarnings(\"ignore\") # to clean up output cells\n",
    "\n",
    "\n",
    "# Load training and validation sets\n",
    "ds_train_ = image_dataset_from_directory(\n",
    "    'train',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "ds_valid_ = image_dataset_from_directory(\n",
    "    'valid',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Data Pipeline\n",
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "ds_train = (\n",
    "    ds_train_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "ds_valid = (\n",
    "    ds_valid_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 32)      2432      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 6)                 196614    \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 291,405\n",
      "Trainable params: 291,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "\n",
    "    # First Convolutional Block\n",
    "    layers.Conv2D(filters=32, kernel_size=5, activation=\"relu\", padding='same',\n",
    "                  # give the input dimensions in the first layer\n",
    "                  # [height, width, color channels(RGB)]\n",
    "                  input_shape=[128, 128, 3]\n",
    "    ),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Second Convolutional Block\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Third Convolutional Block\n",
    "    layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Classifier Head\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units=6, activation=\"relu\"),\n",
    "    layers.Dense(units=1, activation=\"sigmoid\"),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Calling `Model.fit` in graph mode is not supported when the `Model` instance was constructed with eager mode enabled. Please construct your `Model` instance in graph mode or call `Model.fit` with eager mode enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000006?line=2'>3</a>\u001b[0m disable_eager_execution()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000006?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000006?line=5'>6</a>\u001b[0m     optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(epsilon\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000006?line=6'>7</a>\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000006?line=7'>8</a>\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mbinary_accuracy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000006?line=8'>9</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000006?line=10'>11</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000006?line=11'>12</a>\u001b[0m     ds_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000006?line=12'>13</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mds_valid,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000006?line=13'>14</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000006?line=14'>15</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Documents/src/aiexperiments/firsttensor.ipynb#ch0000006?line=15'>16</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.virtualenvs/ai/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.virtualenvs/ai/lib/python3.8/site-packages/keras/utils/version_utils.py:128\u001b[0m, in \u001b[0;36mdisallow_legacy_graph\u001b[0;34m(cls_name, method_name)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[1;32m    123\u001b[0m   error_msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    124\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCalling `\u001b[39m\u001b[39m{\u001b[39;00mcls_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m` in graph mode is not supported \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwhen the `\u001b[39m\u001b[39m{\u001b[39;00mcls_name\u001b[39m}\u001b[39;00m\u001b[39m` instance was constructed with eager mode \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39menabled. Please construct your `\u001b[39m\u001b[39m{\u001b[39;00mcls_name\u001b[39m}\u001b[39;00m\u001b[39m` instance in graph mode or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m call `\u001b[39m\u001b[39m{\u001b[39;00mcls_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m` with eager mode enabled.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 128\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(error_msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Calling `Model.fit` in graph mode is not supported when the `Model` instance was constructed with eager mode enabled. Please construct your `Model` instance in graph mode or call `Model.fit` with eager mode enabled."
     ]
    }
   ],
   "source": [
    "### Aman's code to enable the GPU\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=40,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9b1d4972c802d2f8eb40250b8fdca3289d428ce985ee0b8c467bdb853986922"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
