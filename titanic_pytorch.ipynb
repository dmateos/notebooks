{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle/input/titanic/test.csv\n",
      "kaggle/input/titanic/train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"kaggle/input/titanic/train.csv\")\n",
    "train_data.head()\n",
    "\n",
    "test_data = pd.read_csv(\"kaggle/input/titanic/test.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "\n",
    "\n",
    "device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(output_dim, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "\n",
    "model = Model(5, 1024)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch\n",
       "0       3    1  22.0      1      0\n",
       "1       1    0  38.0      1      0\n",
       "2       3    0  26.0      0      0\n",
       "3       1    0  35.0      1      0\n",
       "4       3    1  35.0      0      0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prep_data(data):\n",
    "    X_Train = data.drop([\"Name\"], axis=1)\n",
    "    X_Train = X_Train.drop([\"Ticket\"], axis=1)\n",
    "    X_Train = X_Train.drop([\"Cabin\"], axis=1)\n",
    "    X_Train = X_Train.drop([\"Embarked\"], axis=1)\n",
    "    X_Train = X_Train.drop([\"PassengerId\"], axis=1)\n",
    "    X_Train = X_Train.drop([\"Fare\"], axis=1)\n",
    "    X_Train[\"Age\"] = X_Train[\"Age\"].fillna(X_Train[\"Age\"].mean())\n",
    "    try:\n",
    "        X_Train = X_Train.drop([\"Survived\"], axis=1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    X_Train[\"Sex\"] = le.fit_transform(X_Train[\"Sex\"])\n",
    "    #X_Train[\"Age\"] = le.fit_transform(X_Train[\"Age\"])\n",
    "    return X_Train\n",
    "\n",
    "X_Train = prep_data(train_data)\n",
    "X_Test = prep_data(test_data)\n",
    "y = train_data[\"Survived\"]\n",
    "\n",
    "X_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.0000,  1.0000, 22.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000, 38.0000,  1.0000,  0.0000],\n",
      "        [ 3.0000,  0.0000, 26.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 3.0000,  0.0000, 29.6991,  1.0000,  2.0000],\n",
      "        [ 1.0000,  1.0000, 26.0000,  0.0000,  0.0000],\n",
      "        [ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000]])\n",
      "Epoch:  0 Loss:  0.2328646332025528\n",
      "Epoch:  1 Loss:  0.379334419965744\n",
      "Epoch:  2 Loss:  0.4127996563911438\n",
      "Epoch:  3 Loss:  0.22731132805347443\n",
      "Epoch:  4 Loss:  0.4780407249927521\n",
      "Epoch:  5 Loss:  0.22036288678646088\n",
      "Epoch:  6 Loss:  0.3055078089237213\n",
      "Epoch:  7 Loss:  0.27775296568870544\n",
      "Epoch:  8 Loss:  0.3677080273628235\n",
      "Epoch:  9 Loss:  0.20003058016300201\n",
      "Epoch:  10 Loss:  0.39250683784484863\n",
      "Epoch:  11 Loss:  0.18470661342144012\n",
      "Epoch:  12 Loss:  0.2395590990781784\n",
      "Epoch:  13 Loss:  0.3973442316055298\n",
      "Epoch:  14 Loss:  0.2830410599708557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s0/xcg0d2_s6tg_2v3r53qlxyl40000gn/T/ipykernel_1681/2898410133.py:15: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = nn.functional.mse_loss(y_pred, y_test)\n",
      "/var/folders/s0/xcg0d2_s6tg_2v3r53qlxyl40000gn/T/ipykernel_1681/2898410133.py:15: UserWarning: Using a target size (torch.Size([27])) that is different to the input size (torch.Size([27, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = nn.functional.mse_loss(y_pred, y_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  15 Loss:  0.4305039048194885\n",
      "Epoch:  16 Loss:  0.23616307973861694\n",
      "Epoch:  17 Loss:  0.2730450928211212\n",
      "Epoch:  18 Loss:  0.2649914622306824\n",
      "Epoch:  19 Loss:  0.1844264566898346\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epoch = 20\n",
    "X_Train = torch.from_numpy(X_Train.to_numpy()).float()\n",
    "X_Test = torch.from_numpy(X_Test.to_numpy()).float()\n",
    "y = torch.from_numpy(y.to_numpy()).float()\n",
    "\n",
    "train_data = DataLoader(TensorDataset(X_Train, y), batch_size=32, shuffle=True)\n",
    "#test_data = DataLoader(TensorDataset(X_Test, y), batch_size=32, shuffle=True)\n",
    "\n",
    "print(X_Train)\n",
    "\n",
    "for n in range(epoch):\n",
    "    for x, y_test in train_data:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = nn.functional.mse_loss(y_pred, y_test)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: \", n, \"Loss: \", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14762558043003082, 0.07900910079479218, 0.04004330933094025, 0.20092009007930756, 0.22963528335094452, 0.31854379177093506, 0.18635831773281097, 0.18552222847938538, 0.29150834679603577, 0.20718184113502502, 0.1761801838874817, 0.0839732214808464, 0.21467538177967072, 0.03354013338685036, 0.07378937304019928, 0.21012212336063385, 0.14148302376270294, 0.25140470266342163, 0.18833351135253906, 0.09770681709051132, 0.0478653758764267, 0.37452176213264465, 0.17743712663650513, 0.24728186428546906, 0.07071051001548767, 0.06478803604841232, 0.2478446066379547, 0.23849919438362122, 0.10596396028995514, 0.1398271918296814, 0.06339913606643677, 0.1771005541086197, 0.1499013602733612, 0.1670031100511551, 0.1532597690820694, 0.27352985739707947, 0.18435579538345337, 0.26204344630241394, 0.21711009740829468, 0.1761801838874817, 0.1221110075712204, 0.17030152678489685, 0.11085707694292068, 0.18375957012176514, 0.08114569634199142, 0.21711009740829468, 0.0880182608962059, 0.1761801838874817, 0.044470805674791336, 0.1461670696735382, 0.19715404510498047, 0.19860585033893585, 0.22021634876728058, 0.13806137442588806, 0.17345011234283447, 0.27395591139793396, 0.1445385366678238, 0.21711009740829468, 0.157085582613945, 0.13833828270435333, 0.28776657581329346, 0.16118472814559937, 0.27825406193733215, 0.252602219581604, 0.27069517970085144, 0.18172019720077515, 0.29150834679603577, 0.08009758591651917, 0.16513991355895996, 0.039088696241378784, 0.23452435433864594, 0.25140470266342163, 0.19384880363941193, 0.18341456353664398, 0.1446007639169693, 0.1549021601676941, 0.1761801838874817, 0.04410296306014061, 0.1754494160413742, 0.23452435433864594, 0.39084261655807495, 0.026422709226608276, 0.0728328675031662, 0.1761801838874817, 0.17345011234283447, 0.157085582613945, 0.2094242423772812, 0.29150834679603577, 0.18435579538345337, 0.44999900460243225, 0.22976671159267426, 0.1761801838874817, 0.18191009759902954, 0.1761801838874817, 0.21154344081878662, 0.21711009740829468, 0.017575228586792946, 0.18565009534358978, 0.2716646194458008, 0.15721887350082397, 0.0892072319984436, 0.17722757160663605, 0.1761801838874817, 0.20889973640441895, 0.2870161831378937, 0.19317089021205902, 0.25140470266342163, 0.1761801838874817, 0.1761801838874817, 0.27343112230300903, 0.1086243987083435, 0.18435579538345337, 0.13833828270435333, 0.2864932417869568, 0.033771030604839325, 0.2548990845680237, 0.1761801838874817, 0.5709835886955261, 0.13284145295619965, 0.17176631093025208, 0.3529540002346039, 0.157085582613945, 0.12881585955619812, 0.19317089021205902, 0.1761801838874817, 0.29779672622680664, 0.24290816485881805, 0.14904600381851196, 0.10383307933807373, 0.22552213072776794, 0.16398407518863678, 0.060086432844400406, 0.17779497802257538, 0.157085582613945, 0.10130763053894043, 0.22552213072776794, 0.20488105714321136, 0.20678110420703888, 0.2434287965297699, 0.10163271427154541, 0.28699061274528503, 0.1578308790922165, 0.03535506874322891, 0.19067324697971344, 0.10120023041963577, 0.1217583417892456, 0.17030152678489685, 0.24290816485881805, 0.17030152678489685, 0.15768662095069885, 0.23848868906497955, 0.1761801838874817, 0.04454023391008377, 0.1461670696735382, 0.2411058247089386, 0.22552213072776794, 0.18721887469291687, 0.2434287965297699, 0.10120023041963577, 0.2166154831647873, 0.18435579538345337, 0.3728960454463959, 0.2160782665014267, 0.1761801838874817, 0.1086243987083435, 0.19745929539203644, 0.07638603448867798, 0.23318906128406525, 0.17743712663650513, 0.252602219581604, 0.1761801838874817, 0.20092009007930756, 0.2109125554561615, 0.1761801838874817, 0.10231786221265793, 0.3131507933139801, 0.2711586058139801, 0.050258126109838486, 0.14229851961135864, 0.03667135164141655, 0.1754494160413742, 0.11239676922559738, 0.26012033224105835, 0.1761801838874817, 0.1826968789100647, 0.11357977986335754, 0.2617587447166443, 0.24077777564525604, 0.08175897598266602, 0.11357977986335754, 0.1319458931684494, 0.17030152678489685, 0.31438541412353516, 0.04206160828471184, 0.38838520646095276, 0.15721887350082397, 0.4050159156322479, 0.29150834679603577, 0.2324722856283188, 0.18435579538345337, 0.18435579538345337, 0.5460842847824097, 0.07045341283082962, 0.37084659934043884, 0.21515792608261108, 0.17030152678489685, 0.15163616836071014, 0.22369828820228577, 0.1578308790922165, 0.21711009740829468, 0.16398407518863678, 0.1761801838874817, 0.2875514328479767, 0.04085427522659302, 0.08342882990837097, 0.10120023041963577, 0.18435579538345337, 0.04340597242116928, 0.0643102303147316, 0.1761801838874817, 0.16482585668563843, 0.25140470266342163, 0.25214293599128723, 0.25140470266342163, 0.06258592754602432, 0.18414804339408875, 0.23410485684871674, 0.18435579538345337, 0.1133769229054451, 0.1354389637708664, 0.31736645102500916, 0.2569197714328766, 0.22772061824798584, 0.1761801838874817, 0.10260375589132309, 0.2600877583026886, 0.030694976449012756, 0.2600877583026886, 0.2638390362262726, 0.07034651190042496, 0.05680227279663086, 0.09569597989320755, 0.07758093625307083, 0.1761801838874817, 0.15824498236179352, 0.09352193027734756, 0.25214293599128723, 0.09257509559392929, 0.17176631093025208, 0.1648171842098236, 0.5561687350273132, 0.2600877583026886, 0.1741204857826233, 0.22552213072776794, 0.16056810319423676, 0.1761801838874817, 0.1761801838874817, 0.19317089021205902, 0.2806750535964966, 0.25140470266342163, 0.12002149969339371, 0.25140470266342163, 0.19155967235565186, 0.5709835886955261, 0.1754494160413742, 0.1761801838874817, 0.17030152678489685, 0.1761801838874817, 0.18435579538345337, 0.28776657581329346, 0.0839732214808464, 0.1761801838874817, 0.1900242567062378, 0.1648171842098236, 0.1761801838874817, 0.2450484335422516, 0.19067324697971344, 0.10092929750680923, 0.15647268295288086, 0.24140731990337372, 0.2434287965297699, 0.49996650218963623, 0.18435579538345337, 0.370851993560791, 0.5485159754753113, 0.1384194791316986, 0.1761801838874817, 0.19715404510498047, 0.1761801838874817, 0.1761801838874817, 0.17030152678489685, 0.18635831773281097, 0.1761801838874817, 0.052799616008996964, 0.1384194791316986, 0.20889973640441895, 0.5523715019226074, 0.1398271918296814, 0.17226830124855042, 0.18565009534358978, 0.16398407518863678, 0.17345011234283447, 0.0992262214422226, 0.22552213072776794, 0.18435579538345337, 0.03229498490691185, 0.151661679148674, 0.49767282605171204, 0.047886863350868225, 0.08664121478796005, 0.27825406193733215, 0.24290816485881805, 0.1761801838874817, 0.13915525376796722, 0.05680227279663086, 0.3019087314605713, 0.04340137913823128, 0.26878681778907776, 0.20092009007930756, 0.1923162043094635, 0.20889973640441895, 0.21711009740829468, 0.20678110420703888, 0.15160372853279114, 0.1209072545170784, 0.23410485684871674, 0.3012050986289978, 0.0839732214808464, 0.1632089614868164, 0.25040724873542786, 0.08326967805624008, 0.11608635634183884, 0.1761801838874817, 0.2564890384674072, 0.20092009007930756, 0.17226830124855042, 0.16118472814559937, 0.1224965825676918, 0.21515792608261108, 0.1761801838874817, 0.27815863490104675, 0.16398407518863678, 0.15544427931308746, 0.049245528876781464, 0.15732210874557495, 0.31242942810058594, 0.20678110420703888, 0.1332339644432068, 0.22369828820228577, 0.17636442184448242, 0.09210628271102905, 0.21515792608261108, 0.27815863490104675, 0.06677193939685822, 0.6106157302856445, 0.06943244487047195, 0.03619087114930153, 0.1761801838874817, 0.1761801838874817, 0.166683629155159, 0.164833664894104, 0.2122841775417328, 0.17636442184448242, 0.20092009007930756, 0.1980629563331604, 0.16695398092269897, 0.157085582613945, 0.252602219581604, 0.09210628271102905, 0.18293923139572144, 0.22445300221443176, 0.17202840745449066, 0.0728328675031662, 0.09477397799491882, 0.05296086519956589, 0.0916522815823555, 0.21132902801036835, 0.25040724873542786, 0.05451975762844086, 0.35572749376296997, 0.1761801838874817, 0.20889973640441895, 0.18435579538345337, 0.257984459400177, 0.17345011234283447, 0.20991361141204834, 0.22552213072776794, 0.05112595111131668, 0.25140470266342163, 0.3541526794433594, 0.22911323606967926, 0.06923792511224747, 0.33731403946876526, 0.08248183131217957, 0.13349048793315887, 0.26012033224105835, 0.22552213072776794, 0.07080517709255219, 0.24290816485881805, 0.17099052667617798, 0.17949803173542023, 0.11047124862670898, 0.2478446066379547, 0.2873861789703369, 0.08516765385866165, 0.2596168518066406, 0.2079029083251953, 0.06106807664036751, 0.18435579538345337, 0.5138028264045715, 0.18435579538345337, 0.11769615858793259, 0.2015761137008667, 0.1761801838874817, 0.1209072545170784, 0.12397357076406479, 0.1761801838874817, 0.15732210874557495]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for n in X_Test:\n",
    "    predictions.append(model(n).item())\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
